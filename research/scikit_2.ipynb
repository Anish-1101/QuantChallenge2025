{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3403ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "train_extra = pd.read_csv('./data/train_new.csv')\n",
    "test_extra = pd.read_csv('./data/test_new.csv')\n",
    "\n",
    "duplicate_train = [c for c in train_extra.columns if c in train.columns]\n",
    "duplicate_test = [c for c in test_extra.columns if c in test.columns]\n",
    "train_extra = train_extra.drop(columns=duplicate_train)\n",
    "test_extra = test_extra.drop(columns=duplicate_test)\n",
    "\n",
    "train = pd.concat([train.reset_index(drop= True), train_extra], axis = 1)\n",
    "test = pd.concat([test.reset_index(drop= True), test_extra], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab87ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eada110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 19) (15996, 18)\n",
      "['time', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'Y1', 'Y2', 'O', 'P']\n",
      "['id', 'time', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)\n",
    "print(list(train.columns))\n",
    "print(list(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4b17446",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = list(train.columns)\n",
    "features = []\n",
    "for col in train.columns:\n",
    "    if col not in [\"Y1\", \"Y2\", \"id\", \"time\"]:\n",
    "        features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab950e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696e675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = train.drop(columns=[\"Y1\", \"Y2\"])\n",
    "test_ids = test.drop(columns=[\"id\"])\n",
    "\n",
    "full = pd.concat([train_targets, test_ids], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c99840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95996, 17)\n"
     ]
    }
   ],
   "source": [
    "print(full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12d6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.sort_values(\"time\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de8b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_list = [1, 2, 3, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8ee7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    series = full[feature]\n",
    "    for k in lag_list:\n",
    "        col_name = f\"{feature}_lag{k}\"\n",
    "        full[col_name] = series.shift(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bf9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = features[0]\n",
    "expected = f\"{example}_lag1\"\n",
    "if expected not in full.columns:\n",
    "    print(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3643d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff1\"] = s.diff(1)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\2075051173.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_diff5\"] = s.diff(5)\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    s = full[feature]\n",
    "    full[f\"{feature}_diff1\"] = s.diff(1)\n",
    "    full[f\"{feature}_diff5\"] = s.diff(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260bcac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3787376751.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n"
     ]
    }
   ],
   "source": [
    "r_windows = [5, 20]\n",
    "for feature in features:\n",
    "    s = full[feature]\n",
    "    for w in r_windows:\n",
    "        full[f\"{feature}_rmean{w}\"] = s.rolling(window = w, min_periods= 1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6573b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
      "C:\\Users\\anish\\AppData\\Local\\Temp\\ipykernel_5600\\3105793696.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()\n"
     ]
    }
   ],
   "source": [
    "for feature in features:\n",
    "    s = full[feature]\n",
    "    for w in r_windows:\n",
    "        full[f\"{feature}_rstd{w}\"] = s.rolling(window=w, min_periods=1).std().fillna(0.0)\n",
    "\n",
    "for feature in features:\n",
    "    s = full[feature]\n",
    "    full[f\"{feature}_rmin5\"] = s.rolling(window = 5, min_periods = 1).min()\n",
    "    full[f\"{feature}_rmax5\"] = s.rolling(window = 5, min_periods = 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e47e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f476accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_train_rows = len(train)\n",
    "train_fe = full.iloc[:no_train_rows].copy()\n",
    "test_fe = full.iloc[no_train_rows:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d0a50f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 225)\n",
      "(15996, 225)\n"
     ]
    }
   ],
   "source": [
    "print(train_fe.shape)\n",
    "print(test_fe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "696cd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_max = train_fe[\"time\"].max()\n",
    "test_time_min = test_fe[\"time\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed7bae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80004\n",
      "80005\n"
     ]
    }
   ],
   "source": [
    "print(int(train_time_max))\n",
    "print(int(test_time_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b807c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_fe.columns:\n",
    "    if col != \"time\":\n",
    "        train_fe[col] = np.tanh(train_fe[col])\n",
    "        test_fe[col] = np.tanh(test_fe[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858adb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lag = 10\n",
    "train_xy = train_fe.iloc[max_lag:].copy()\n",
    "train_xy[[\"Y1\",\"Y2\"]] = train[[\"Y1\",\"Y2\"]].iloc[max_lag:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f41efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_xy.drop(columns=[\"Y1\", \"Y2\", \"time\"])\n",
    "y1 = train_xy[\"Y1\"].values\n",
    "y2 = train_xy[\"Y2\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3259db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79990, 224)\n",
      "79990\n",
      "79990\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(len(y1))\n",
    "print(len(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b69ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3798519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 5)\n",
    "fold = 0\n",
    "for index, value in tscv.split(x):\n",
    "    train_end = int(train_xy.iloc[index][\"time\"].max())\n",
    "    value_start = int(train_xy.iloc[value][\"time\"].min())\n",
    "    value_end = int(train_xy.iloc[value][\"time\"].max())\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5985d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66673\n",
      "66674\n"
     ]
    }
   ],
   "source": [
    "print(train_end)\n",
    "print(value_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07fb7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(x, y, splits = 5):\n",
    "    tscv2 = TimeSeriesSplit(n_splits= splits)\n",
    "    r2_scores = []\n",
    "    hgb_params = dict(max_iter = 300, learning_rate = 0.06, max_leaf_nodes = 128, min_samples_leaf= 10, l2_regularization=0.0, random_state= 40)\n",
    "    et_params = dict(n_estimators = 1200, min_samples_leaf = 3, max_features = 0.7, bootstrap = True, n_jobs = -1, max_samples = 0.9, random_state = 40, max_depth = None)\n",
    "\n",
    "    fold_id = 0\n",
    "    for index, value in tscv2.split(x):\n",
    "        x_train = x.iloc[index]\n",
    "        x_value = x.iloc[value]\n",
    "        y_train = y[index]\n",
    "        y_value = y[value]\n",
    "\n",
    "        hgb = HistGradientBoostingRegressor(**hgb_params)\n",
    "        et = ExtraTreesRegressor(**et_params)\n",
    "\n",
    "        hgb.fit(x_train, y_train)\n",
    "        et.fit(x_train, y_train)\n",
    "\n",
    "        predict_hgb = hgb.predict(x_value)\n",
    "        predict_et = et.predict(x_value)\n",
    "\n",
    "        predict_b = 0.5 * predict_hgb + 0.5 * predict_et\n",
    "        fold_r2 = r2_score(y_value, predict_b)\n",
    "        r2_scores.append(fold_r2)\n",
    "\n",
    "        fold_id += 1\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    print(r2_scores.mean())\n",
    "    return r2_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b685df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361159556081642\n",
      "0.6598891708050927\n"
     ]
    }
   ],
   "source": [
    "r2_y1 = cv(x, y1, splits = 5)\n",
    "r2_y2 = cv(x, y2, splits = 5)\n",
    "avg_cv = (r2_y1.mean() + r2_y2.mean()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfb8a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6355930793311155\n"
     ]
    }
   ],
   "source": [
    "print((r2_y1[-1] + r2_y2[-1]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a334be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_fe.drop(columns = [\"time\"]).copy()\n",
    "x_test = x_test[x.columns]\n",
    "\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_cols = list(x.columns)\n",
    "test_cols = list(x_test.columns)\n",
    "\n",
    "def cv_single(x, y, model, splits = 5):\n",
    "    tscv3 = TimeSeriesSplit(n_splits= splits)\n",
    "    scores = []\n",
    "    for index, value in tscv3.split(x):\n",
    "        m = model.__class__(**model.get_params())\n",
    "        m.fit(x.iloc[index], y[index])\n",
    "        scores.append(r2_score(y[value], m.predict(x.iloc[value])))\n",
    "    return np.array(scores)\n",
    "\n",
    "hgb_cv = HistGradientBoostingRegressor(max_iter = 300, learning_rate = 0.06, max_leaf_nodes = 128, min_samples_leaf= 10, l2_regularization=0.0, random_state= 40)\n",
    "et_cv = ExtraTreesRegressor(n_estimators = 1200, min_samples_leaf = 3, max_features = 0.7, bootstrap = True, n_jobs = -1, max_samples = 0.9, random_state = 40, max_depth = None)\n",
    "\n",
    "r2_hgb_y1 = cv_single(x, y1, hgb_cv, splits = 5)\n",
    "r2_et_y1 = cv_single(x, y1, et_cv, splits = 5)\n",
    "\n",
    "r2_hgb_y2 = cv_single(x, y2, hgb_cv, splits = 5)\n",
    "r2_et_y2 = cv_single(x, y2, et_cv, splits = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9382df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = dict(\n",
    "    n_estimators = 1200, learning_rate = 0.03,\n",
    "    num_leaves = 63, max_depth = -1,\n",
    "    subsample = 0.9, colsample_bytree = 0.8,\n",
    "    reg_lambda = 1.0, reg_alpha = 0.0,\n",
    "    min_child_samples = 20, n_jobs = -1, random_state = 40\n",
    ")\n",
    "\n",
    "xgb_params = dict(\n",
    "    n_estimators = 1200, learning_rate = 0.03,\n",
    "    max_depth = 8, subsample = 0.9, colsample_bytree = 0.8,\n",
    "    reg_lambda = 1.0, reg_alpha = 0.0,\n",
    "    min_child_weight = 2, tree_method = \"hist\", n_jobs = -1, random_state = 40\n",
    ")\n",
    "\n",
    "cat_params = dict(\n",
    "    depth = 8, learning_rate = 0.03, iterations = 1200,\n",
    "    l2_leaf_reg = 3.0, loss_function = \"RMSE\",\n",
    "    random_seed = 40, verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbbe134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_y1 = {\"hgb\": r2_hgb_y1.mean(), \"et\": r2_et_y1.mean()}\n",
    "cv_scores_y2 = {\"hgb\": r2_hgb_y2.mean(), \"et\": r2_et_y2.mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23892e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50648\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score 0.005911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50700\n",
      "[LightGBM] [Info] Number of data points in the train set: 26666, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.001769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50722\n",
      "[LightGBM] [Info] Number of data points in the train set: 39997, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score 0.000432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50750\n",
      "[LightGBM] [Info] Number of data points in the train set: 53328, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score 0.001174\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50768\n",
      "[LightGBM] [Info] Number of data points in the train set: 66659, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score 0.000159\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50648\n",
      "[LightGBM] [Info] Number of data points in the train set: 13335, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score 0.082633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50700\n",
      "[LightGBM] [Info] Number of data points in the train set: 26666, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.102811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50722\n",
      "[LightGBM] [Info] Number of data points in the train set: 39997, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.122973\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50750\n",
      "[LightGBM] [Info] Number of data points in the train set: 53328, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.100132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50768\n",
      "[LightGBM] [Info] Number of data points in the train set: 66659, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.119048\n"
     ]
    }
   ],
   "source": [
    "r2_lgbm_y1 = cv_single(x, y1, LGBMRegressor(**lgbm_params), splits = 5).mean()\n",
    "r2_lgbm_y2 = cv_single(x, y2, LGBMRegressor(**lgbm_params), splits = 5).mean()\n",
    "cv_scores_y1[\"lgbm\"] = r2_lgbm_y1\n",
    "cv_scores_y2[\"lgbm\"] = r2_lgbm_y2\n",
    "\n",
    "r2_xgb_y1 = cv_single(x, y1, XGBRegressor(**xgb_params), splits = 5).mean()\n",
    "r2_xgb_y2 = cv_single(x, y2, XGBRegressor(**xgb_params), splits = 5).mean()\n",
    "cv_scores_y1[\"xgb\"] = r2_xgb_y1\n",
    "cv_scores_y2[\"xgb\"] = r2_xgb_y2\n",
    "\n",
    "r2_cat_y1 = cv_single(x, y1, CatBoostRegressor(**cat_params), splits = 5).mean()\n",
    "r2_cat_y2 = cv_single(x, y2, CatBoostRegressor(**cat_params), splits = 5).mean()\n",
    "cv_scores_y1[\"cat\"] = r2_cat_y1\n",
    "cv_scores_y2[\"cat\"] = r2_cat_y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad3f1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_m_y1 = [name for name, s in cv_scores_y1.items() if s > 0.0]\n",
    "use_m_y2 = [name for name, s in cv_scores_y2.items() if s > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b20b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hgb', 'et', 'lgbm', 'xgb', 'cat']\n",
      "['hgb', 'et', 'lgbm', 'xgb', 'cat']\n"
     ]
    }
   ],
   "source": [
    "print(use_m_y1)\n",
    "print(use_m_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b76f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y1 final models\n",
    "final_hgb_y1 = HistGradientBoostingRegressor(max_iter = 700, learning_rate = 0.06, max_leaf_nodes = 128, min_samples_leaf= 10, l2_regularization=0.0, random_state= 40).fit(x, y1)\n",
    "final_et_y1 = ExtraTreesRegressor(n_estimators = 1200, min_samples_leaf = 3, max_features = 0.7, bootstrap = True, n_jobs = -1, max_samples = 0.9, random_state = 40, max_depth = None).fit(x, y1)\n",
    "\n",
    "# Y2 final models\n",
    "final_hgb_y2 = HistGradientBoostingRegressor(max_iter = 700, learning_rate = 0.06, max_leaf_nodes = 128, min_samples_leaf= 10, l2_regularization=0.0, random_state= 40).fit(x, y2)\n",
    "final_et_y2 = ExtraTreesRegressor(n_estimators = 1200, min_samples_leaf = 3, max_features = 0.7, bootstrap = True, n_jobs = -1, max_samples = 0.9, random_state = 40, max_depth = None).fit(x, y2)\n",
    "\n",
    "models_y1 = {\"hgb\": final_hgb_y1, \"et\": final_et_y1}\n",
    "models_y2 = {\"hgb\": final_hgb_y2, \"et\": final_et_y2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47775f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50775\n",
      "[LightGBM] [Info] Number of data points in the train set: 79990, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.002809\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50775\n",
      "[LightGBM] [Info] Number of data points in the train set: 79990, number of used features: 224\n",
      "[LightGBM] [Info] Start training from score -0.061143\n"
     ]
    }
   ],
   "source": [
    "models_y1[\"lgbm\"] = LGBMRegressor(**lgbm_params).fit(x,y1)\n",
    "models_y2[\"lgbm\"] = LGBMRegressor(**lgbm_params).fit(x,y2)\n",
    "\n",
    "models_y1[\"xgb\"] = XGBRegressor(**xgb_params).fit(x,y1)\n",
    "models_y2[\"xgb\"] = XGBRegressor(**xgb_params).fit(x,y2)\n",
    "\n",
    "models_y1[\"cat\"] = CatBoostRegressor(**cat_params).fit(x,y1)\n",
    "models_y2[\"cat\"] = CatBoostRegressor(**cat_params).fit(x,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74ec9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = [models_y1[name].predict(x_test) for name in use_m_y1]\n",
    "P2 = [models_y2[name].predict(x_test) for name in use_m_y2]\n",
    "predicted_y1 = np.mean(P1, axis = 0)\n",
    "predicted_y2 = np.mean(P2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "418604bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007413192861159855\n",
      "0.780470236344406\n",
      "-0.15071913279524848\n",
      "0.5855276034697707\n"
     ]
    }
   ],
   "source": [
    "print(float(np.mean(predicted_y1)))\n",
    "print(float(np.std(predicted_y1)))\n",
    "print(float(np.mean(predicted_y2)))\n",
    "print(float(np.std(predicted_y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f70fd99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15996, 3)\n"
     ]
    }
   ],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'Y1': predicted_y1,\n",
    "    'Y2': predicted_y2,\n",
    "})\n",
    "\n",
    "sub.to_csv('preds.csv', index=False)\n",
    "print(sub.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
